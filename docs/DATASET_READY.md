# âœ… Dataset Ready for Cosmos-Reason2 Fine-tuning!

## Summary

We now have a **production-ready dataset** of 1,943 synthetic chess board images with FEN annotations, formatted for Cosmos-Reason2 fine-tuning.

## Dataset Statistics

| Split | Samples | Percentage | Purpose |
|-------|---------|------------|---------|
| **Train** | 1,554 | 80% | Model training |
| **Val** | 194 | 10% | Validation during training |
| **Test** | 195 | 10% | Final evaluation |
| **Total** | **1,943** | 100% | Complete dataset |

## Dataset Characteristics

### Images
- **Format:** 1280x1280 JPEG
- **Content:** Synthetic chess boards with random positions
- **Viewpoint:** Angled overhead (egocentric perspective)
- **Diversity:** 1,943 unique random positions

### Annotations
- **Format:** FEN (Forsyth-Edwards Notation)
- **Completeness:** Full FEN strings (position + metadata)
- **Board corners:** Normalized coordinates (0-1 range)
- **Source:** Converted from synthetic generator

### Sample Entry

```json
{
    "image": "/path/to/chessboards/1895.jpg",
    "conversations": [
        {
            "role": "user",
            "content": "Describe this chess position in FEN notation."
        },
        {
            "role": "assistant",
            "content": "2N3qr/1K1B1bK1/2NrQr1k/6qN/Kp4R1/Kb1BkB1k/3NK1N1/bR2k1nP w - - 0 1"
        }
    ],
    "metadata": {
        "corners": [[0.55, 0.18], [0.19, 0.45], [0.80, 0.55], [0.45, 0.79]],
        "source": "synthetic_chessboard_dataset"
    }
}
```

## Files Created

```
cosmos-chessbot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chessboards/              # Original dataset (1,943 images + annotations)
â”‚   â”œâ”€â”€ chess_fen_train.jsonl     # 1,554 training samples âœ…
â”‚   â”œâ”€â”€ chess_fen_val.jsonl       # 194 validation samples âœ…
â”‚   â””â”€â”€ chess_fen_test.jsonl      # 195 test samples âœ…
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ convert_chessboard_dataset.py  # Conversion script âœ…
â””â”€â”€ DATASET_READY.md              # This file âœ…
```

## Why This Dataset is Excellent

âœ… **Large enough** - 1,943 samples (50-100 minimum recommended)
âœ… **High quality** - Synthetic renders, consistent quality
âœ… **Angled views** - Matches egocentric robot camera
âœ… **Diverse positions** - Random piece placements
âœ… **Proper format** - JSONL conversations for Cosmos fine-tuning
âœ… **Well-split** - 80/10/10 train/val/test

## Comparison to Requirements

| Requirement | Recommended | Our Dataset | Status |
|-------------|-------------|-------------|--------|
| Min samples | 50-100 | 1,943 | âœ… Excellent |
| Image quality | High | 1280x1280 | âœ… Perfect |
| Viewpoint | Angled | Angled overhead | âœ… Matches |
| Format | JSONL | JSONL | âœ… Correct |
| Labels | FEN | FEN | âœ… Complete |

## Next Steps: Fine-tuning

### 1. Set Up Training Environment

**Hardware Requirements:**
- **GPU:** H100 (80GB) or A100 (40GB)
- **RAM:** 32GB+
- **Storage:** 50GB for model + dataset

**Cloud Options:**
- RunPod: $1.99/hour (H100 PCIe)
- Lambda Labs: $1.29/hour (A100)
- Vast.ai: Variable pricing

### 2. Install Dependencies

```bash
# On training machine
pip install transformers>=4.36.0
pip install peft>=0.7.0
pip install datasets>=2.14.0
pip install accelerate>=0.25.0
pip install bitsandbytes>=0.41.0
pip install wandb  # Optional: for experiment tracking
```

### 3. Download Base Model

```python
from transformers import AutoModelForVision2Seq, AutoProcessor

model = AutoModelForVision2Seq.from_pretrained(
    "nvidia/Cosmos-Reason2-8B",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
processor = AutoProcessor.from_pretrained("nvidia/Cosmos-Reason2-8B")
```

### 4. Training Script

Adapt from Cosmos Cookbook recipe:
- **Recipe:** https://nvidia-cosmos.github.io/cosmos-cookbook/recipes/post_training/reason2/intelligent-transportation/post_training.html
- **Task:** Chess FEN detection (similar to traffic scene understanding)
- **Method:** LoRA fine-tuning (efficient, fast)

### 5. Training Configuration

```yaml
# Hyperparameters (from recipe)
learning_rate: 2e-5
batch_size: 4
gradient_accumulation_steps: 4
num_epochs: 3-5
warmup_steps: 100
max_length: 512

# LoRA config
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]

# Hardware
mixed_precision: bf16
gradient_checkpointing: true
```

### 6. Expected Results

Based on recipe and dataset size:

| Metric | Base Model | After Fine-tuning |
|--------|------------|-------------------|
| **Accuracy** | 0% | **70-90%** |
| **Training time** | - | 2-4 hours |
| **GPU cost** | - | $4-8 |
| **Inference speed** | Same | Same |

## Timeline

### This Week (Already Done âœ…)
- âœ… Explored all alternative approaches
- âœ… Identified fine-tuning as solution
- âœ… Converted 1,943 images to training format
- âœ… Created train/val/test splits

### Next Week
- [ ] Set up H100/A100 cloud instance
- [ ] Install dependencies and download base model
- [ ] Adapt training script from recipe
- [ ] Run fine-tuning (2-4 hours)
- [ ] Evaluate on test set

### Week After
- [ ] Integrate fine-tuned model into orchestrator
- [ ] Test end-to-end on robot
- [ ] Record demo video
- [ ] Prepare competition submission

## Key Advantages

1. **Proven approach** - Recipe shows dramatic improvement
2. **Large dataset** - 1,943 samples (19x minimum requirement)
3. **Perfect format** - Ready for training, no more preprocessing
4. **Angled views** - Matches robot camera perspective
5. **Fast training** - 2-4 hours on H100
6. **Low cost** - $5-10 total

## Commands Summary

```bash
# Verify dataset
head -1 data/chess_fen_train.jsonl | python -m json.tool

# Count samples
wc -l data/chess_fen_*.jsonl

# Random sample
shuf -n 1 data/chess_fen_train.jsonl | python -m json.tool

# View an image
open data/chessboards/0.jpg
```

## Files to Submit with H100 Job

1. `data/chess_fen_train.jsonl` (1,554 samples)
2. `data/chess_fen_val.jsonl` (194 samples)
3. `data/chess_fen_test.jsonl` (195 samples)
4. `data/chessboards/` (all images referenced in JSONL)
5. Training script (to be created from recipe)

## Success Metrics

After fine-tuning, we expect:

- âœ… **>70% accuracy** on test set (195 samples)
- âœ… **>80% accuracy** on validation set (194 samples)
- âœ… **Works on real robot images** (egocentric angles)
- âœ… **Fast inference** (<1 second per image)

## Final Status

ðŸŽ¯ **READY TO TRAIN!**

We have:
- âœ… Large, high-quality dataset (1,943 samples)
- âœ… Proper format (JSONL conversations)
- âœ… Train/val/test splits
- âœ… Clear training plan
- âœ… Proven recipe to follow

**Next step:** Set up H100 GPU and start training!
